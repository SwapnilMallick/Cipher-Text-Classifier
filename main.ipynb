{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training, dev and unlabeled test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following provides a starting code (Python 3) of how to read the labeled training and dev cipher text, and unlabeled test cipher text, into lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Convolution1D\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = [], [], [] \n",
    "train_labels, dev_labels = [], [] \n",
    "train_text, dev_text = [], [] \n",
    "clean_train, clean_dev = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Training Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16220\n",
      "[[0, 'lkêcê yoúc cêêö y#êjl lw mówám Újám j Úêê# ütlk Úol lkêú z#ê ctöé8ú ówl xoóóú éê#xw#öê#c .'], [0, '6êcétlê jolêot8 zc éê#xw#öjóáê , tl zc j #jlkê# 8tcl8êcc jöÚ8ê 6wüó lkê öt668ê wx lkê #wj6 , ükê#ê lkê lkêöjltá t#wótêc j#ê lww wÚ2twoc jó6 lkê cê+oj8 éw8tltác lww cöoy .'], [0, 'tx lktc kw8t6jú öw2tê tc coééwcê6 lw Úê j ytxl , cwöêÚw6ú oóü#jééê6 tl êj#8ú , lwwm wol j88 lkê yww6 cloxx , jó6 8êxl Úêktó6 lkê á#jé ( 8tlê#j88ú ) .']]\n"
     ]
    }
   ],
   "source": [
    "for x in open('./train_enc.tsv', encoding='utf-8'):\n",
    "    x = x.rstrip('\\n\\r').split('\\t')\n",
    "    # x[0] will be the label (0 or 1), and x[1] will be the ciphertext sentence.\n",
    "    x[0] = int(x[0]) \n",
    "    train.append(x)\n",
    "print (len(train))\n",
    "print (train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16220\n",
      "[0, 0, 0, 1, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "for x in open('./train_enc.tsv', encoding='utf-8'):\n",
    "    x = x.rstrip('\\n\\r').split('\\t')\n",
    "    # x[0] will be the label (0 or 1), and x[1] will be the ciphertext sentence.\n",
    "    x[0] = int(x[0])\n",
    "    train_labels.append(x[0])\n",
    "print(len(train_labels))\n",
    "print(train_labels[:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16220\n",
      "['lkêcê yoúc cêêö y#êjl lw mówám Újám j Úêê# ütlk Úol lkêú z#ê ctöé8ú ówl xoóóú éê#xw#öê#c .', '6êcétlê jolêot8 zc éê#xw#öjóáê , tl zc j #jlkê# 8tcl8êcc jöÚ8ê 6wüó lkê öt668ê wx lkê #wj6 , ükê#ê lkê lkêöjltá t#wótêc j#ê lww wÚ2twoc jó6 lkê cê+oj8 éw8tltác lww cöoy .', 'tx lktc kw8t6jú öw2tê tc coééwcê6 lw Úê j ytxl , cwöêÚw6ú oóü#jééê6 tl êj#8ú , lwwm wol j88 lkê yww6 cloxx , jó6 8êxl Úêktó6 lkê á#jé ( 8tlê#j88ú ) .', 'vocl ükêó úwo lktóm lkjl ê2ê#ú éwcctÚ8ê jóy8ê kjc Úêêó ê+kjoclê6 Úú 6wáoöêólj#tjóc , jówlkê# óêü xt8ö êöê#yêc ütlk úêl jówlkê# #êöj#mjÚ8ê úêl ckwámtóy8ú 8tll8ê7mówüó éê#céêált2ê .', 'yt2ê á#ê6tl lw ê2ê#úwóê x#wö #wÚtócwó 6wüó lw lkê mêú y#té lkjl lktc Úw86 öw2ê üw#mc .']\n"
     ]
    }
   ],
   "source": [
    "for x in open('./train_enc.tsv', encoding='utf-8'):\n",
    "    x = x.rstrip('\\n\\r').split('\\t')\n",
    "    # x[0] will be the label (0 or 1), and x[1] will be the ciphertext sentence.\n",
    "    x[1] = str(x[1])\n",
    "    train_text.append(x[1])\n",
    "print(len(train_text))\n",
    "print(train_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16220\n",
      "['lkêcê yoúc cêêö y#êjl lw mówám Újám j Úêê# ütlk Úol lkêú z#ê ctöé8ú ówl xoóóú éê#xw#öê#c', '6êcétlê jolêot8 zc éê#xw#öjóáê tl zc j #jlkê# 8tcl8êcc jöÚ8ê 6wüó lkê öt668ê wx lkê #wj6 ükê#ê lkê lkêöjltá t#wótêc j#ê lww wÚ2twoc jó6 lkê cê+oj8 éw8tltác lww cöoy', 'tx lktc kw8t6jú öw2tê tc coééwcê6 lw Úê j ytxl cwöêÚw6ú oóü#jééê6 tl êj#8ú lwwm wol j88 lkê yww6 cloxx jó6 8êxl Úêktó6 lkê á#jé ( 8tlê#j88ú )', 'vocl ükêó úwo lktóm lkjl ê2ê#ú éwcctÚ8ê jóy8ê kjc Úêêó ê+kjoclê6 Úú 6wáoöêólj#tjóc jówlkê# óêü xt8ö êöê#yêc ütlk úêl jówlkê# #êöj#mjÚ8ê úêl ckwámtóy8ú 8tll8ê7mówüó éê#céêált2ê', 'yt2ê á#ê6tl lw ê2ê#úwóê x#wö #wÚtócwó 6wüó lw lkê mêú y#té lkjl lktc Úw86 öw2ê üw#mc']\n"
     ]
    }
   ],
   "source": [
    "for i in train_text:\n",
    "    i = i.replace('.', '')\n",
    "    i = i.replace(',', '')\n",
    "    i = i.replace('  ', ' ')\n",
    "    i = i.rstrip()\n",
    "    clean_train.append(i)\n",
    "print(len(clean_train))\n",
    "print(clean_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(clean_train)\n",
    "train_sequence = tokenizer.texts_to_sequences(clean_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = pad_sequences(train_sequence, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 268  778  338 ...    0    0    0]\n",
      " [ 262 4411   17 ...    0    0    0]\n",
      " [  61   21 1570 ...    0    0    0]\n",
      " ...\n",
      " [   2    2  240 ...    0    0    0]\n",
      " [3834 4236   70 ...    0    0    0]\n",
      " [9920    4  496 ...    0    0    0]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(train_padded)\n",
    "print(type(train_padded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Validation Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2027\n",
      "[[1, 'ów8jó Ú#j2ê8ú l#êj6c ükê#ê xêü jöê#tájó xt8öc 6j#ê lw 6ê82ê 77 tólw lkê üw#86 wx jöÚt2j8êóáê jó6 jöÚtyotlú <<<'], [0, 'ê2êó öo#ékú zc ê+éê#l áwötá ltötóy jó6 xjöê6 ákj#tcöj áj ózl #êcáoê lktc êxxw#l .'], [1, 'üt88 jcco#ê68ú #jóm jc wóê wx lkê á8ê2ê#êcl , öwcl 6êáêélt2ê8ú jöoctóy áwöê6têc wx lkê úêj# .']]\n"
     ]
    }
   ],
   "source": [
    "for x in open('./dev_enc.tsv', encoding='utf-8'):\n",
    "    x = x.rstrip('\\n\\r').split('\\t')\n",
    "    # x[0] will be the label (0 or 1), and x[1] will be the ciphertext sentence.\n",
    "    x[0] = int(x[0]) \n",
    "    dev.append(x)\n",
    "print (len(dev))\n",
    "print (dev[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2027\n",
      "[1, 0, 1, 1, 1, 1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for x in open('./dev_enc.tsv', encoding='utf-8'):\n",
    "    x = x.rstrip('\\n\\r').split('\\t')\n",
    "    # x[0] will be the label (0 or 1), and x[1] will be the ciphertext sentence.\n",
    "    x[0] = int(x[0]) \n",
    "    dev_labels.append(x[0])\n",
    "print(len(dev_labels))\n",
    "print(dev_labels[:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2027\n",
      "['ów8jó Ú#j2ê8ú l#êj6c ükê#ê xêü jöê#tájó xt8öc 6j#ê lw 6ê82ê 77 tólw lkê üw#86 wx jöÚt2j8êóáê jó6 jöÚtyotlú <<<', 'ê2êó öo#ékú zc ê+éê#l áwötá ltötóy jó6 xjöê6 ákj#tcöj áj ózl #êcáoê lktc êxxw#l .', 'üt88 jcco#ê68ú #jóm jc wóê wx lkê á8ê2ê#êcl , öwcl 6êáêélt2ê8ú jöoctóy áwöê6têc wx lkê úêj# .', 'tl kjc j ájxxêtójlê6 , c8wééú Ú#t88tjóáê , céj#m8tóy ütlk t6êjc úwo ütck kj6 Úêêó 6ê2ê8wéê6 ütlk öw#ê áj#ê , Úol jótöjlê6 Úú jó êóê#yú lkjl éolc lkê 6oltxo8 êxxw#lc wx öw#ê 6tcáté8tóê6 y#j6ê7y#oÚÚê#c lw ckjöê .', 'lww öoák wx clw#úlê88tóy öw2êc jüjú x#wö cw8wó6azc cwátj8 á#tlt!oê , ájcltóy tlc jo6têóáê jc lkjl wx tólê88êáloj8 8êálw# tó áwólêöé8jltwó wx lkê jolêo#zc é#wxêcctwój8 tóvo#têc .']\n"
     ]
    }
   ],
   "source": [
    "for x in open('./dev_enc.tsv', encoding='utf-8'):\n",
    "    x = x.rstrip('\\n\\r').split('\\t')\n",
    "    # x[0] will be the label (0 or 1), and x[1] will be the ciphertext sentence.\n",
    "    x[1] = str(x[1]) \n",
    "    dev_text.append(x[1])\n",
    "print(len(dev_text))\n",
    "print(dev_text[:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2027\n",
      "['ów8jó Ú#j2ê8ú l#êj6c ükê#ê xêü jöê#tájó xt8öc 6j#ê lw 6ê82ê 77 tólw lkê üw#86 wx jöÚt2j8êóáê jó6 jöÚtyotlú <<<', 'ê2êó öo#ékú zc ê+éê#l áwötá ltötóy jó6 xjöê6 ákj#tcöj áj ózl #êcáoê lktc êxxw#l', 'üt88 jcco#ê68ú #jóm jc wóê wx lkê á8ê2ê#êcl öwcl 6êáêélt2ê8ú jöoctóy áwöê6têc wx lkê úêj#', 'tl kjc j ájxxêtójlê6 c8wééú Ú#t88tjóáê céj#m8tóy ütlk t6êjc úwo ütck kj6 Úêêó 6ê2ê8wéê6 ütlk öw#ê áj#ê Úol jótöjlê6 Úú jó êóê#yú lkjl éolc lkê 6oltxo8 êxxw#lc wx öw#ê 6tcáté8tóê6 y#j6ê7y#oÚÚê#c lw ckjöê', 'lww öoák wx clw#úlê88tóy öw2êc jüjú x#wö cw8wó6azc cwátj8 á#tlt!oê ájcltóy tlc jo6têóáê jc lkjl wx tólê88êáloj8 8êálw# tó áwólêöé8jltwó wx lkê jolêo#zc é#wxêcctwój8 tóvo#têc']\n"
     ]
    }
   ],
   "source": [
    "for i in dev_text:\n",
    "    i = i.replace('.', '')\n",
    "    i = i.replace(',', '')\n",
    "    i = i.replace('  ', ' ')\n",
    "    i = i.rstrip()\n",
    "    clean_dev.append(i)\n",
    "print(len(clean_dev))\n",
    "print(clean_dev[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_2 = Tokenizer()\n",
    "tokenizer_2.fit_on_texts(clean_dev)\n",
    "dev_sequence = tokenizer.texts_to_sequences(clean_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_padded = pad_sequences(dev_sequence, maxlen = 64, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6423     8 14936 ...     0     0     0]\n",
      " [   78   424  1266 ...     0     0     0]\n",
      " [   84  1290  5582 ...     0     0     0]\n",
      " ...\n",
      " [    2    13  1312 ...     0     0     0]\n",
      " [   72   908    60 ...     0     0     0]\n",
      " [    6   346    11 ...     0     0     0]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(dev_padded)\n",
    "print(type(dev_padded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Test Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2028\n",
      "['j 6t6jáltá jó6 6o88 6wáoöêólj#ú y8w#txútóy cwxlüj#ê jój#ákú .', 'ówlktóy cltámc , #êj88ú , ê+áêél j 8tóyê#tóy á#êêétóêcc wóê xêê8c x#wö Úêtóy 6#jyyê6 lk#woyk j cj6 , cw#6t6 oót2ê#cê wx yoóc , 6#oyc , j2j#táê jó6 6jöjyê6 6#êjöc .', 'öo#ékú jó6 üt8cwó jáloj88ú öjmê j é#êllú yww6 lêjö <<< Úol lkê é#wvêál co##woó6tóy lkêö tc 6tcl#êcctóy8ú #wlê .']\n"
     ]
    }
   ],
   "source": [
    "for x in open('./test_enc_unlabeled.tsv', encoding='utf-8'):\n",
    "    x = x.rstrip('\\n\\r')\n",
    "    test.append(x)\n",
    "print (len(test))\n",
    "print (test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2028\n",
      "['j 6t6jáltá jó6 6o88 6wáoöêólj#ú y8w#txútóy cwxlüj#ê jój#ákú', 'ówlktóy cltámc #êj88ú ê+áêél j 8tóyê#tóy á#êêétóêcc wóê xêê8c x#wö Úêtóy 6#jyyê6 lk#woyk j cj6 cw#6t6 oót2ê#cê wx yoóc 6#oyc j2j#táê jó6 6jöjyê6 6#êjöc', 'öo#ékú jó6 üt8cwó jáloj88ú öjmê j é#êllú yww6 lêjö <<< Úol lkê é#wvêál co##woó6tóy lkêö tc 6tcl#êcctóy8ú #wlê', 'lkê xt8ö üjc é#w6oáê6 Úú vê##ú Ú#oámkêtöê# jó6 6t#êálê6 Úú vwê8 cákoöjákê# jó6 #êx8êálc lkê üw#cl wx lkêt# ckj88wü clú8êc 1 üt868ú w2ê#é#w6oáê6 tój6ê!ojlê8ú öwlt2jlê6 ê2ê#ú clêé wx lkê üjú jó6 6êöwy#jéktáj88ú lj#yêlê6 lw é8êjcê ê2ê#ú wóê ( jó6 ów wóê )', 'tl zc cé8jck ütlkwol lkê vwmêc']\n"
     ]
    }
   ],
   "source": [
    "for i in test:\n",
    "    i = i.replace('.', '')\n",
    "    i = i.replace(',', '')\n",
    "    i = i.replace('  ', ' ')\n",
    "    i = i.rstrip()\n",
    "    clean_test.append(i)\n",
    "print(len(clean_test))\n",
    "print(clean_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_3 = Tokenizer()\n",
    "tokenizer_3.fit_on_texts(clean_test)\n",
    "test_sequence = tokenizer.texts_to_sequences(clean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padded = pad_sequences(test_sequence, maxlen =64, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2 3850    3 ...    0    0    0]\n",
      " [ 171 3990  153 ...    0    0    0]\n",
      " [ 424 1266    3 ...    0    0    0]\n",
      " ...\n",
      " [   2   86 1596 ...    0    0    0]\n",
      " [ 911  269    4 ...    0    0    0]\n",
      " [  22 2532  459 ...    0    0    0]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(test_padded)\n",
    "print(type(test_padded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code Body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may choose to experiment with different methods using your program. However, you need to embed the training and inference processes at here. We will use your prediction on the unlabeled test data to grade, while checking this part to understand how your method has produced the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = 15420, output_dim = 50))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "#model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(32, activation=\"selu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation=\"selu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "earlystopping = EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 5, \n",
    "                                        restore_best_weights = True)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 50)          771000    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 64)          21248     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 794,873\n",
      "Trainable params: 794,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16220 samples, validate on 2027 samples\n",
      "Epoch 1/10\n",
      " - 69s - loss: 0.4959 - acc: 0.7453 - val_loss: 0.3649 - val_acc: 0.8436\n",
      "Epoch 2/10\n",
      " - 61s - loss: 0.2416 - acc: 0.9057 - val_loss: 0.3396 - val_acc: 0.8742\n",
      "Epoch 3/10\n",
      " - 61s - loss: 0.1429 - acc: 0.9491 - val_loss: 0.3736 - val_acc: 0.8722\n",
      "Epoch 4/10\n",
      " - 61s - loss: 0.1003 - acc: 0.9666 - val_loss: 0.3828 - val_acc: 0.8816\n",
      "Epoch 5/10\n",
      " - 62s - loss: 0.0790 - acc: 0.9733 - val_loss: 0.3962 - val_acc: 0.8777\n",
      "Epoch 6/10\n",
      " - 64s - loss: 0.0662 - acc: 0.9772 - val_loss: 0.4195 - val_acc: 0.8712\n",
      "Epoch 7/10\n",
      " - 63s - loss: 0.0597 - acc: 0.9791 - val_loss: 0.4274 - val_acc: 0.8747\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = model.fit(train_padded, train_labels, epochs=num_epochs, validation_data=(dev_padded, dev_labels), verbose=2,  callbacks = [earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict_classes(test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eventually, results need to be a list of 2028 0 or 1's\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Prediction Result File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to submit a prediction result file. It should have 2028 lines, every line should be either 0 or 1, which is your model's prediction on the respective test set instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose you had your model's predictions on the 2028 test cases read from test_enc_unlabeled.tsv, and \n",
    "#those results are in the list called 'results'\n",
    "assert (len(results) == 2028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the results are not float numbers, but intergers 0 and 1\n",
    "results = [int(x) for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your prediction results to 'upload_predictions.txt' and upload that later\n",
    "with open('upload_predictions.txt', 'w', encoding = 'utf-8') as fp:\n",
    "    for x in results:\n",
    "        fp.write(str(x) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
